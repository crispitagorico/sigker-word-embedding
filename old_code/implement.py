import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

from gensim.test.utils import datapath
from gensim import utils
import gensim.models
import gensim.downloader as api
from gensim.downloader import base_dir

import smart_open
import io
import os
import torch

from modules import preprocess as preproc
from modules import nnNaive as nnN
from modules import plotTSNE as tsne

def head(path, size):
    with smart_open.open(path) as fin:
        return io.StringIO(fin.read(size))

# def generate_input_data():
#     lee_path = datapath('lee_background.cor')
#     ls = gensim.models.word2vec.LineSentence(lee_path)
#     ls.name = '25kB'
#     yield ls
#
#     # text8_path = api.load('wiki-english-20171001').fn
#     text8_path = api.load('text8').fn
#     labels = ('1MB', '10MB', '50MB', '100MB')
#     sizes = (1024 ** 2, 10 * 1024 ** 2, 50 * 1024 ** 2, 100 * 1024 ** 2)
#     for l, s in zip(labels, sizes):
#         ls = gensim.models.word2vec.LineSentence(head(text8_path, s))
#         ls.name = l
#         yield ls

def generate_input_data():
    # path = "/home/nina17/Desktop/NLPProject/wiki-2010-split/xaa"
    path = "/home/nina17/Desktop/NLPProject/1000-parole-ita"
    ls = preproc.newLineSentence(head(path, 1024 ** 2),letter_embedding=True)
    #### SHOULD ALSO TAKE A LOOK AT  gensim.models.word2vec.PathLineSentence() ######
    ls.name = 'words'
    yield ls

input_data = list(generate_input_data())
emb_dim = 2
voc = preproc.vocabulary(input_data[0], embedding_dim=emb_dim, letter_embedding=True)

# use gpu if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")   # understand if you need this
model = nnN.Autoencoder(len(voc.wv.index2word), emb_dim).to(device)

nnN.runModel(voc, model, epochs=100)
print(model.embeddings.weight)   ### this is where the embedding matrix is stored
tsne.tsne_plot(voc, emb_dim)


#### RESULTS OF EXPERIMENTS

# res = torch.tensor([[ 0.7463,  0.2271],
#         [-1.1559,  1.6835],
#         [-0.4065,  1.3543],
#         [-0.3724, -0.5809],
#         [ 0.4681,  0.6336],
#         [-0.3204, -0.4187],
#         [-2.3368, -0.1695],
#         [-0.1095, -0.0448],
#         [ 1.2856,  0.3391],
#         [-0.9478,  0.1232],
#         [-0.2847, -0.0519],
#         [-1.0675, -1.5752],
#         [-0.0880,  1.2102],
#         [ 0.6071, -0.1757],
#         [-0.4611, -0.2177],
#         [-0.8961, -1.4958],
#         [ 0.0480, -1.5080],
#         [-0.5220,  0.0231],
#         [-0.8004, -1.2660],
#         [ 1.1142, -0.6214],
#         [ 0.0279, -1.3485],
#         [ 1.4415,  1.0522],
#         [ 0.7607, -0.8663],
#         [ 0.2927,  1.6601],
#         [ 1.1829,  0.7841],
#         [-0.8242,  0.6917]])
#

# res = torch.tensor([[ 0.5275,  1.9833],
#         [-0.0119, -1.4964],
#         [ 0.7722,  2.2925],
#         [ 0.6035,  0.5497],
#         [-0.0533,  0.5187],
#         [ 0.8713,  0.2885],
#         [-0.1097,  0.9275],
#         [-0.5322, -0.0574],
#         [ 0.4296,  1.8421],
#         [-0.5616,  0.1112],
#         [ 0.9497,  0.5675],
#         [-0.2549,  0.9243],
#         [ 0.0675, -0.5303],
#         [-0.0196, -0.0126],
#         [-1.4323,  0.1565],
#         [-0.5893, -1.2948],
#         [-0.7236, -0.6257],
#         [ 0.5833, -0.3957],
#         [-0.0092,  0.3124],
#         [-0.0384, -0.0954],
#         [ 0.1971,  0.6959],
#         [ 0.5857, -2.0804],
#         [-1.7127,  0.0292],
#         [-0.4481, -1.3795],
#         [ 0.6353, -0.3794],
#         [ 1.4309, -1.5199]])
#


# res = torch.tensor([[-0.6139,  0.7437],
#         [-0.6364,  1.2655],
#         [ 1.3438, -0.4879],
#         [ 0.2908,  1.0822],
#         [ 0.5449, -0.3294],
#         [-1.8875, -0.4411],
#         [ 1.2466,  1.0898],
#         [-0.0097, -0.3669],
#         [ 0.9740, -1.5768],
#         [-0.0125, -0.9546],
#         [ 1.1838, -2.3481],
#         [-0.3856, -0.0108],
#         [ 0.3249, -0.5892],
#         [ 0.4187, -0.7903],
#         [-0.2643,  2.1378],
#         [-0.0554, -2.3416],
#         [-0.0697, -0.5443],
#         [-0.6758,  1.0744],
#         [ 0.4662,  1.1382],
#         [-0.5318,  1.8742],
#         [ 0.2659,  0.1625],
#         [ 1.6161, -1.1633],
#         [ 0.5634,  0.3326],
#         [ 2.1837, -1.0745],
#         [-0.7315, -0.8319],
# #         [-0.2171,  1.1428]])
#
# res = torch.tensor([[-2.6960e-01, -1.0128e+00],
#         [-1.7007e+00, -1.6610e+00],
#         [-1.4887e+00, -7.6599e-02],
#         [-1.6275e-01,  7.7535e-01],
#         [ 8.6562e-01,  4.1011e-01],
#         [-6.7973e-01, -6.5240e-02],
#         [ 6.0368e-01, -5.2591e-02],
#         [-5.7233e-01,  5.5074e-01],
#         [-1.6570e+00, -6.0877e-01],
#         [ 1.0621e+00,  3.3265e-01],
#         [-4.6475e-03, -1.7174e+00],
#         [-7.6236e-01, -3.9904e-01],
#         [ 1.4008e+00,  4.3147e-01],
#         [-8.4322e-01, -5.7476e-04],
#         [-1.5053e+00, -2.1821e-01],
#         [-4.1468e-01, -1.0514e+00],
#         [-7.2995e-01, -6.3112e-02],
#         [-7.2449e-02, -8.1976e-01],
#         [-1.0640e+00, -4.4570e-01],
#         [-1.4395e+00, -8.4170e-02],
#         [-8.4049e-01, -2.4825e-01],
#         [-1.2077e+00, -4.2687e-01],
#         [-5.8157e-01, -6.6791e-02],
#         [-1.4879e+00, -2.9563e-01],
#         [ 6.4496e-01,  4.6149e-01],
#         [-6.7729e-01, -6.7141e-01]])
#
# res = torch.tensor([[-0.3764,  0.4840],
#         [ 0.4690,  0.2401],
#         [-0.4442, -0.2197],
#         [ 1.1368,  0.4976],
#         [-0.0791, -0.8572],
#         [-0.3949,  1.0133],
#         [-0.4908, -0.0792],
#         [-1.5773, -0.0542],
#         [-0.3850,  0.5440],
#         [-0.5168, -0.0627],
#         [-1.0370,  0.5936],
#         [-0.0726, -1.1246],
#         [-1.2606, -1.1939],
#         [-0.7607, -0.3697],
#         [-0.0877, -0.5014],
#         [-0.2802, -0.2726],
#         [-0.5127, -0.5034],
#         [-0.0804, -0.8523],
#         [-0.6079, -2.9802],
#         [ 0.7194, -0.5700],
#         [-1.7751, -0.9067],
#         [ 0.1751, -0.0919],
#         [-0.0854, -0.9301],
#         [-0.2316, -0.9920],
#         [ 1.2532,  0.5795],
#         [-0.0909, -0.3812]])
#
# res = torch.tensor([[ 1.0857, -0.0388],
#         [-0.2567, -0.4770],
#         [ 1.0900, -0.1410],
#         [ 1.6076, -0.0553],
#         [-1.9014, -0.0065],
#         [ 1.5494, -1.4124],
#         [ 1.0140, -0.4874],
#         [ 0.6507, -1.7663],
#         [ 0.8125, -0.0665],
#         [-0.0125, -0.0578],
#         [-0.0989, -0.0842],
#         [-0.0406,  0.8308],
#         [-1.1075, -1.2106],
#         [-0.5985, -1.3227],
#         [ 0.7294, -0.0874],
#         [ 1.5591, -0.0271],
#         [-0.1589, -0.0784],
#         [-0.1934, -0.2744],
#         [-0.1076, -0.8175],
#         [-1.5271, -0.9985],
#         [-0.4953, -0.8717],
#         [-0.0959, -0.3908],
#         [ 1.2308, -0.1181],
#         [-0.5593, -0.1031],
#         [-0.3009, -1.2048],
#         [ 0.8566,  0.9742]])
# voc.wv.vectors = res
#
#
# cl.tsne_plot(voc)
